<!DOCTYPE html>
<html lang="pt-BR">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Gravação e Análise Musical</title>
  <script src="https://unpkg.com/@tonaljs/tonal@4.6.4/dist/tonal.min.js"></script>
  <style>
    body { font-family: Arial, sans-serif; text-align: center; padding: 20px; }
    button { padding: 10px 20px; margin: 10px; font-size: 16px; }
    #output { margin-top: 20px; text-align: left; max-width: 600px; margin-left: auto; margin-right: auto; }
  </style>
</head>
<body>
  <h1>Gravação e Análise Musical</h1>
  <button id="startBtn">Iniciar Gravação</button>
  <button id="stopBtn" disabled>Parar Gravação</button>
  <audio id="audioPlayback" controls></audio>
  <div id="output"></div>

  <script>
    let audioContext, analyser, mediaRecorder, chunks = [], stream;
    let notes = [];
    const noteFrequencies = {
      'C4': 261.63, 'C#4': 277.18, 'D4': 293.66, 'D#4': 311.13, 'E4': 329.63,
      'F4': 349.23, 'F#4': 369.99, 'G4': 392.00, 'G#4': 415.30, 'A4': 440.00,
      'A#4': 466.16, 'B4': 493.88
    };

    // Função para converter frequência em nota
    function frequencyToNote(frequency) {
      let closestNote = null, minDiff = Infinity;
      for (const [note, freq] of Object.entries(noteFrequencies)) {
        const diff = Math.abs(frequency - freq);
        if (diff < minDiff) {
          minDiff = diff;
          closestNote = note;
        }
      }
      return closestNote;
    }

    // Função para estimar tonalidade (simplificada)
    function estimateTonality(notes) {
      const noteCounts = {};
      notes.forEach(note => {
        noteCounts[note] = (noteCounts[note] || 0) + 1;
      });
      const mostFrequent = Object.keys(noteCounts).reduce((a, b) => noteCounts[a] > noteCounts[b] ? a : b, null);
      const scale = Tonal.Scale.get(`${mostFrequent} major`).notes;
      return { tonic: mostFrequent, scale };
    }

    // Função de autocorrelação para detectar pitch
    function detectPitch(dataArray, sampleRate) {
      const SIZE = dataArray.length;
      const MAX_SAMPLES = Math.floor(SIZE / 2);
      const MIN_SAMPLES = 20;
      let bestOffset = -1, bestCorrelation = 0, rms = 0;

      // Calcular RMS para verificar se há sinal suficiente
      for (let i = 0; i < SIZE; i++) {
        rms += dataArray[i] * dataArray[i];
      }
      rms = Math.sqrt(rms / SIZE);
      if (rms < 0.01) return null; // Sinal muito fraco

      // Autocorrelação
      for (let offset = MIN_SAMPLES; offset < MAX_SAMPLES; offset++) {
        let correlation = 0;
        for (let i = 0; i < SIZE - offset; i++) {
          correlation += Math.abs(dataArray[i] * dataArray[i + offset]);
        }
        correlation = correlation / (SIZE - offset);
        if (correlation > bestCorrelation) {
          bestCorrelation = correlation;
          bestOffset = offset;
        }
      }

      if (bestCorrelation < 0.1) return null; // Correlação insuficiente
      return sampleRate / bestOffset; // Frequência em Hz
    }

    // Função para processar áudio e detectar notas
    function processAudio() {
      const bufferLength = analyser.fftSize = 2048;
      const dataArray = new Float32Array(bufferLength);

      function analyze() {
        analyser.getFloatTimeDomainData(dataArray);
        const pitch = detectPitch(dataArray, audioContext.sampleRate);
        if (pitch && pitch > 50 && pitch < 1000) {
          const note = frequencyToNote(pitch);
          if (note && !notes.includes(note)) notes.push(note);
        }
        if (mediaRecorder.state === 'recording') {
          requestAnimationFrame(analyze);
        }
      }
      analyze();
    }

    // Configurar gravação
    async function setupRecording() {
      stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      audioContext = new AudioContext();
      analyser = audioContext.createAnalyser();
      const source = audioContext.createMediaStreamSource(stream);
      source.connect(analyser);

      mediaRecorder = new MediaRecorder(stream);
      mediaRecorder.ondataavailable = e => chunks.push(e.data);
      mediaRecorder.onstop = async () => {
        const blob = new Blob(chunks, { type: 'audio/wav' });
        chunks = [];
        const audioURL = URL.createObjectURL(blob);
        document.getElementById('audioPlayback').src = audioURL;

        // Exibir resultados
        const { tonic, scale } = estimateTonality(notes);
        document.getElementById('output').innerHTML = `
          <h3>Resultados da Análise</h3>
          <p><strong>Notas Detectadas:</strong> ${notes.join(', ')}</p>
          <p><strong>Tonalidade Estimada:</strong> ${tonic} maior</p>
          <p><strong>Escala:</strong> ${scale.join(', ')}</p>
        `;
        notes = []; // Resetar notas para próxima gravação
      };
    }

    // Event listeners para botões
    document.getElementById('startBtn').addEventListener('click', async () => {
      await setupRecording();
      mediaRecorder.start();
      processAudio();
      document.getElementById('startBtn').disabled = true;
      document.getElementById('stopBtn').disabled = false;
    });

    document.getElementById('stopBtn').addEventListener('click', () => {
      mediaRecorder.stop();
      stream.getTracks().forEach(track => track.stop());
      audioContext.close();
      document.getElementById('startBtn').disabled = false;
      document.getElementById('stopBtn').disabled = true;
    });
  </script>
</body>
</html>
